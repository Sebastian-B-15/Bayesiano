<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sebastian Baeza">

<title>Metodos bayesianos - Test de hipótesis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="Metodos-bayesianos_Test-de-Hipotesis_files/libs/clipboard/clipboard.min.js"></script>
<script src="Metodos-bayesianos_Test-de-Hipotesis_files/libs/quarto-html/quarto.js"></script>
<script src="Metodos-bayesianos_Test-de-Hipotesis_files/libs/quarto-html/popper.min.js"></script>
<script src="Metodos-bayesianos_Test-de-Hipotesis_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Metodos-bayesianos_Test-de-Hipotesis_files/libs/quarto-html/anchor.min.js"></script>
<link href="Metodos-bayesianos_Test-de-Hipotesis_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Metodos-bayesianos_Test-de-Hipotesis_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Metodos-bayesianos_Test-de-Hipotesis_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Metodos-bayesianos_Test-de-Hipotesis_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Metodos-bayesianos_Test-de-Hipotesis_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#metodos-bayesianos" id="toc-metodos-bayesianos" class="nav-link active" data-scroll-target="#metodos-bayesianos">Metodos bayesianos</a>
  <ul class="collapse">
  <li><a href="#tests-de-hipótesis" id="toc-tests-de-hipótesis" class="nav-link" data-scroll-target="#tests-de-hipótesis">Tests de Hipótesis</a>
  <ul class="collapse">
  <li><a href="#función-de-pérdida-0-1-generalizada" id="toc-función-de-pérdida-0-1-generalizada" class="nav-link" data-scroll-target="#función-de-pérdida-0-1-generalizada">Función de pérdida 0-1 generalizada</a></li>
  <li><a href="#hipótesis-puntuales" id="toc-hipótesis-puntuales" class="nav-link" data-scroll-target="#hipótesis-puntuales">Hipótesis puntuales</a></li>
  <li><a href="#probabilidad-a-posteriori" id="toc-probabilidad-a-posteriori" class="nav-link" data-scroll-target="#probabilidad-a-posteriori">Probabilidad a posteriori</a></li>
  <li><a href="#factor-de-bayes" id="toc-factor-de-bayes" class="nav-link" data-scroll-target="#factor-de-bayes">Factor de Bayes</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Metodos bayesianos - Test de hipótesis</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Autor/a</div>
    <div class="quarto-title-meta-contents">
             <p>Sebastian Baeza </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="metodos-bayesianos" class="level1">
<h1>Metodos bayesianos</h1>
<section id="tests-de-hipótesis" class="level2">
<h2 class="anchored" data-anchor-id="tests-de-hipótesis">Tests de Hipótesis</h2>
<p>El problema clásico de test de hipótesis, también corresponde a un problema de decisión. Supongamos que <span class="math inline">\(\theta\)</span> puede tomar valores en <span class="math inline">\(\Theta\)</span>, entonces las hipótesis a probar son de la forma <span class="math inline">\(H_0: \theta \in \Theta_0\)</span> versus <span class="math inline">\(H_1: \theta \in \Theta_1\)</span>, donde <span class="math inline">\(\{ \Theta_0, \Theta_1 \}\)</span> es una partición de <span class="math inline">\(\Theta\)</span>.</p>
<p>Siguiendo con el problema de decisión, definiremos los estados desconocidos de la naturaleza como <span class="math inline">\(\Omega = \{w_0 := "\theta \in \Theta_0", w_1 := "\theta \in \Theta_1" \}\)</span>, o sea nos interesa cuál es la hipótesis cierta, no el valor específico de <span class="math inline">\(\theta\)</span>. Las decisiones posibles a tomar son <span class="math inline">\(A = \{ a_0, a_1 \}\)</span>, que son concluir <span class="math inline">\(H_0\)</span> y <span class="math inline">\(H_1\)</span> respectivamente.</p>
<p>Luego, la función de pérdida <span class="math inline">\(l(a_i, w_i), i=1,2\)</span> toma a lo mucho mucho cuatro valores, ya que su dominio es <span class="math inline">\(\{ (a_0, w_0), (a_1, w_0), (a_0, w_1), (a_1, w_1) \}\)</span>.</p>
<section id="función-de-pérdida-0-1-generalizada" class="level3">
<h3 class="anchored" data-anchor-id="función-de-pérdida-0-1-generalizada">Función de pérdida 0-1 generalizada</h3>
<p>Dado un problema de decisión tipo test de hipótesis, la función de pérdida 0-1 generalizada se dice que es aquella de la forma: <span class="math inline">\(l(a_0, w_0) = l(a_1, w_1) = 0\)</span> (aceptar/concluir la hipotesis correcta), <span class="math inline">\(l(a_1, w_0) = c_1 &gt; 0\)</span>, <span class="math inline">\(l(a_0, w_1) = c_2 &gt; 0\)</span>.</p>
<section id="regla-de-decisión-óptima" class="level4">
<h4 class="anchored" data-anchor-id="regla-de-decisión-óptima">Regla de decisión óptima</h4>
<p>Bajo esta función de pérdida y contexto, supongamos que deseamos tomar una decisión a posteriori, entonces la decisión óptima que minimiza la pérdida esperada es:</p>
<ul>
<li>Aceptar <span class="math inline">\(H_1: \theta \in \Theta_1\)</span> si <span class="math inline">\(P(\theta \in \Theta_0|x) &lt; \frac{c_2}{c_1 + c_2}\)</span>.</li>
<li>Aceptar <span class="math inline">\(H_0: \theta \in \Theta_0\)</span> si <span class="math inline">\(P(\theta \in \Theta_0|x) &gt; \frac{c_2}{c_1 + c_2}\)</span>.</li>
</ul>
<details>
<summary>
Demostración
</summary>
Podemos expresar la pérdida esperada como una matriz, en este caso podemos expresar <span class="math inline">\(l(a_i,w_i)\)</span> como una matriz y multiplicar cada fila por la probabilidad de <span class="math inline">\(w_0: P(\theta \in \theta_0)\)</span> y <span class="math inline">\(w_1: P(\theta \in \Theta_1)\)</span>: <span class="math display">\[(l(a_i, w_i) \cdot P(w_i))_{i=1,2} = \begin{bmatrix} &amp; a_0 &amp; a_1 \\ w_0 &amp; 0 &amp; c_1 \cdot P(\theta \in \Theta_0) \\ w_1 &amp; c_2 \cdot P(\theta \in \Theta_1) &amp; 0 \end{bmatrix}\]</span> Luego, la pérdida esperada al escoger <span class="math inline">\(a_0\)</span> es la suma de la primera columna: <span class="math inline">\(c_2 \cdot P(\theta \in \Theta_1)\)</span>, mientras que la de escoger <span class="math inline">\(a_1\)</span> es la suma de la segunda: <span class="math inline">\(c_1 \cdot P(\theta \in \Theta_0)\)</span>. Entonces escogemos la menor pérdida esperada, supongamos que decidimos <span class="math inline">\(a_0: \textup{Concluir } H_0\)</span>, entonces es porque <span class="math inline">\(c_2 \cdot P(\theta \in \Theta_1) &lt; c_1 \cdot P(\theta \in \Theta_0) \Rightarrow c_2 \cdot (1 - P(\theta \in \Theta_0)) &lt; c_1 \cdot P(\theta \in \Theta_0) \Rightarrow c_2 &lt; (c_1 + c_2) P(\theta \in \Theta_0)\)</span>. Luego, es análogo para demostrar el caso en que se decide <span class="math inline">\(a_1\)</span>.
</details>
<details>
<summary>
Ejercicio 1
</summary>
<p>Considere la secuencia de variables aleatorias permutables <span class="math inline">\(x_1 , ..., x_n\)</span> , con verosimilitud <span class="math inline">\(N(\theta, \sigma^2)\)</span>, con distribución a priori <span class="math inline">\(N(\mu, \tau^2)\)</span> para <span class="math inline">\(\theta\)</span>, donde <span class="math inline">\(\sigma^2, \mu, \tau^2\)</span> son conocidos. Interesa testear:<br> $H_0: _0 $ versus <span class="math inline">\(H_1: \theta &lt; \theta_0\)</span>, con <span class="math inline">\(\theta_0\)</span> un valor fijo en <span class="math inline">\(\mathbb{R}\)</span>. Encuentre la regla de decisión óptima bajo una función de pérdida 0-1 generalizada.</p>
<p>Se sabe que en un modelo normal-normal como esta, la distribución a posteriori es una <span class="math inline">\(N\left(v^2 \left( \frac{\mu}{\tau^2} + \frac{\sum_{i=1}^n x_i}{\sigma^2} \right), v^2 \right)\)</span>, con <span class="math inline">\(v^2 = \left( \frac{1}{\tau^2} + \frac{n}{\sigma^2} \right)^{-1}\)</span>.</p>
Luego, se tiene que <span class="math inline">\(P(\theta \geq \theta_0) = P \left( v^{-2}\theta - \left( \frac{\mu}{\tau^2} + \frac{\sum_{i=1}^n x_i}{\sigma^2} \right) \geq v^{-2}\theta_0 - \left( \frac{\mu}{\tau^2} + \frac{\sum_{i=1}^n x_i}{\sigma^2} \right) \right)\)</span><br> <span class="math inline">\(= 1 - P \left( Z &lt; v^{-2}\theta_0 - \left( \frac{\mu}{\tau^2} + \frac{\sum_{i=1}^n x_i}{\sigma^2} \right) \right)\)</span><br> Entonces concluimos <span class="math inline">\(H_1\)</span> si <span class="math inline">\(1 - \phi \left( v^{-2}\theta_0 - \left( \frac{\mu}{\tau^2} + \frac{\sum_{i=1}^n x_i}{\sigma^2} \right) \right) &lt; \frac{c_2}{c_1 + c_2}\)</span>. (En Rstudio otra opción es usar 1 - pnorm(<span class="math inline">\(\theta_0\)</span>, <span class="math inline">\(\left( \frac{\mu}{\tau^2} + \frac{\sum_{i=1}^n x_i}{\sigma^2} \right)\)</span>, <span class="math inline">\(v\)</span>))
</details>
</section>
</section>
<section id="hipótesis-puntuales" class="level3">
<h3 class="anchored" data-anchor-id="hipótesis-puntuales">Hipótesis puntuales</h3>
<p>Consideren las hipótesis <span class="math inline">\(H_0: \theta = \theta_0\)</span> versus <span class="math inline">\(H_1: \theta \neq \theta_0\)</span>. Entonces si la distribución de <span class="math inline">\(\theta\)</span> (a priori/posteriori según corresponda) es continua, <span class="math inline">\(P(\theta = \theta_0) = 0\)</span>, por lo que nunca podríamos aceptar <span class="math inline">\(H_0\)</span> (bajo la función de pérdida anterior).</p>
<p>Luego debemos asignarle una probabilidad a este evento, supongamos <span class="math inline">\(0 &lt; p_0 = P(\theta = \theta_0)\)</span>. Entonces la nueva fdp ajustada sería: <span class="math display">\[p(\theta) = p_0 \cdot I_{(\theta = \theta_0)} + (1 - p_0) \cdot p'(\theta)\]</span> Donde <span class="math inline">\(p'(\theta)\)</span> es la fdp original de <span class="math inline">\(\theta\)</span> a priori/posteriori.<br> Como <span class="math inline">\(P(\theta = \theta_0) = p_0\)</span>, entonces <span class="math inline">\(P(\theta \neq \theta_0) = 1 - p_0\)</span>. De esta forma, escalamos la fdp original por <span class="math inline">\((1 - p_0)\)</span> cuando <span class="math inline">\(\theta\)</span> es diferente de <span class="math inline">\(\theta_0\)</span>. Ahora esta v.a. es continua en todos los puntos, pero en particular en <span class="math inline">\(\theta_0\)</span> la variable mantiene una parte discreta que en la fdp se expresa como <span class="math inline">\(p_0\)</span> y la propia continua que se expresa por <span class="math inline">\((1-p_0)p'(\theta)\)</span>. Si sumamos la parte discreta a la parte continua intregrada, obtenemos que es <span class="math inline">\(1\)</span>.</p>
</section>
<section id="probabilidad-a-posteriori" class="level3">
<h3 class="anchored" data-anchor-id="probabilidad-a-posteriori">Probabilidad a posteriori</h3>
<p>Supongamos que la probabilidad de <span class="math inline">\(\theta = \theta_0\)</span> a posteriori es <span class="math inline">\(p_1\)</span> (<span class="math inline">\(p_1 = P(\theta = \theta_0|x)\)</span>). Si la probabilidad a priori es como se definió anteriormente <span class="math inline">\(P(\theta = \theta_0) = p_0\)</span>, entonces esta se puede actualizar usando: <span class="math display">\[\frac{p_1}{1-p_1} = \frac{p_0}{1-p_0} \cdot \frac{p(x|\theta_0)}{\int_{\theta} p(x|\theta)p(\theta) d\theta}\]</span> La razón de usar <span class="math inline">\(\frac{p_1}{1-p_1}\)</span>, lo que se define como “chances” de <span class="math inline">\(p_1\)</span>, es que cambios en <span class="math inline">\(p_1\)</span> se ven más claramente de esta forma.</p>
<details>
<summary>
Demostración
</summary>
Usando la fdp ajustada <span class="math inline">\(p(\theta)\)</span>, notemos que por teorema de Bayes: <br> <span class="math inline">\(p_1 = P(\theta = \theta_0|x) = p(x|\theta_0) \cdot P(\theta = \theta_0)/p(x) = p(x|\theta_0) \cdot p_0/p(x)\)</span> <br> Mientras que por otro lado, también por Bayes: <br> <span class="math inline">\(1 - p_1 = P(\theta \neq \theta_0|x)\)</span> <br> <span class="math inline">\(= p(x, \theta \neq \theta_0)/p(x)\)</span> <br> <span class="math inline">\(= \int_{\Theta - \{ \theta_0 \}} p(x|\theta)p(\theta) d\theta /p(x)\)</span> <br> <span class="math inline">\(= \int_{\Theta - \{ \theta_0 \}} p(x|\theta)p'(\theta) d\theta (1-p_0) /p(x)\)</span> <br> Entonces, si dividimos ambas expresiones, se sigue que: <br> <span class="math inline">\(\frac{p_1}{1-p_1} = \frac{p_0}{1-p_0} \cdot \frac{p(x|\theta_0)}{\int_{\Theta - \{ \theta_0 \}} p(x|\theta)p'(\theta) d\theta}\)</span>
</details>
</section>
<section id="factor-de-bayes" class="level3">
<h3 class="anchored" data-anchor-id="factor-de-bayes">Factor de Bayes</h3>
<details>
<summary>
Interpretación Factor de Bayes
</summary>
Notemos que el factor <span class="math inline">\(\frac{p_0}{1-p_0}\)</span> es independiente de la evidencia y solo depende de alguna suposición inicial sobre la probabilidad de <span class="math inline">\(\theta = \theta_0\)</span> (no importa si es una v.a. continua o discreta, a priori siempre “inventamos” su probabilidad, aunque es más claro en el caso continuo), que puede o no ser errada. Por otro lado, al factor <span class="math inline">\(\boldsymbol{\frac{p(x|\theta_0)}{\int_{\Theta} p(x|\theta)p'(\theta) d\theta}}\)</span>, lo denominaremos <b>Factor de Bayes (BF)</b>, y este si depende de la evidencia, por lo cuál va variando y nos dice si aumentar o disminuir la probabilidad supuesta <span class="math inline">\(p_0\)</span>, para obtener actualizarla a la posteriori <span class="math inline">\(p_1\)</span> (más cercano a lo que es real). Si <b>BF</b> es grande, entonces <span class="math inline">\(\frac{p_1}{1-p_1}\)</span> y <span class="math inline">\(p_1\)</span> serán grandes, por lo tanto la probabilidad de <span class="math inline">\(H_0\)</span> será más grande de lo que estimamos a priori. Por lo tanto, en este contexto sería razonable aceptar <span class="math inline">\(H_0\)</span>.
</details>
<p>El factor de actualización de las chances de <span class="math inline">\(H_0\)</span>, corresponde al <b>Factor de Bayes</b>. Luego para el caso <span class="math inline">\(H_0: \theta = \theta_0\)</span> versus <span class="math inline">\(H_1: \theta \neq \theta_0\)</span>: <span class="math display">\[BF = \frac{p(x|\theta_0)}{\int_{\Theta} p(x|\theta)p'(\theta) d\theta}\]</span></p>
En otros tipos de hipótesis también el factor de Bayes tiene forma similar, <span class="math inline">\(BF = \frac{P(\theta \in \Theta_0)}{P(\theta \in \Theta_1)}\)</span>:
<ol>
<li>
Suponiendo dos hipótesis compuestas; <span class="math inline">\(H_0: \theta \in \Theta_0\)</span> versus <span class="math inline">\(H_1: \theta \in \Theta_1\)</span>: <span class="math display">\[BF = \frac{\int_{\Theta_0} p(x|\theta)p'(\theta) d\theta}{\int_{\Theta_1} p(x|\theta)p'(\theta) d\theta}\]</span>
</li>
<li>
Suponiendo dos hipótesis simples; <span class="math inline">\(H_0: \theta = \theta_0\)</span> versus <span class="math inline">\(H_1: \theta = \theta_1\)</span>: <span class="math display">\[BF = \frac{p(x|\theta_0)}{p(x|\theta_1)}\]</span> *En este caso proponemos también probabilidades para <span class="math inline">\(P(\theta = \theta_0)\)</span> y <span class="math inline">\(P(\theta = \theta_1)\)</span> en caso de que <span class="math inline">\(\theta\)</span> tenga distribución a priori continua. Luego, esto no es relevante al final, porque estas probabilidades no formarán parte del factor de Bayes.
</li>
</ol>
<section id="razón-de-verosimilitudes-integradas" class="level4">
<h4 class="anchored" data-anchor-id="razón-de-verosimilitudes-integradas">Razón de verosimilitudes integradas</h4>
<p>Dos hipótesis que contrasten modelos, por ejemplo <span class="math inline">\(H_0: \textup{El modelo es } M_i\)</span> versus <span class="math inline">\(H_1: \textup{El modelo es } M_j\)</span>, pueden compararse con sus razones a posteriori: <span class="math display">\[\frac{P(M_i|x)}{P(M_j|x)} = \frac{P(x|M_i)}{P(x|M_j)} \cdot \frac{P(M_i)}{P(M_j)}\]</span> Donde el factor <span class="math inline">\(\frac{P(x|M_i)}{P(x|M_j)}\)</span>, se denomina razón de verosimilitudes integradas (si se expande como integrales queda claro porqué el nombre, ver más abajo).</p>
<p>El Factor de Bayes a considerar en este test de contraste de modelos, es la razón de verosimilitudes integradas: <span class="math display">\[\frac{P(x|M_i)}{P(x|M_j)} = \frac{\int_{\Theta_0} p_{M_i}(x | \theta) p_{M_i}(\theta) d\theta}{\int_{\Theta_1} p_{M_j}(x | \theta) p_{M_j}(\theta) d\theta}\]</span> Donde <span class="math inline">\(p_{M_k}(x|\theta)\)</span> es la verosimilitud en el caso del modelo <span class="math inline">\(M_k\)</span>, mientras que <span class="math inline">\(p_{M_k}(\theta)\)</span> es la priori propuesta en el modelo <span class="math inline">\(M_k\)</span>.</p>
</section>
<section id="evidencia-dada-por-el-factor-de-bayes" class="level4">
<h4 class="anchored" data-anchor-id="evidencia-dada-por-el-factor-de-bayes">Evidencia dada por el Factor de Bayes</h4>
<p>Si aplicamos logaritmo en base 10 al BF, entonces concluimos <span class="math inline">\(H_0\)</span> con diferente fuerza:<br> - Si <span class="math inline">\(\log_{10} BF &lt; 0\)</span>, se concluye <span class="math inline">\(H_1\)</span>, para conocer con que fuerza se puede calcular <span class="math inline">\(-\log_{10} BF = \log_{10} BF_{H_1}\)</span> y usar este mismo criterio.<br> - Si <span class="math inline">\(0 \leq \log_{10} BF &lt; 1/2\)</span>, la fuerza de la evidencia a favor de <span class="math inline">\(H_0\)</span> apenas y merece una mención.<br> - Si <span class="math inline">\(\frac{1}{2} \leq \log_{10} BF &lt; 2\)</span>, la evidencia a favor de <span class="math inline">\(H_0\)</span> es fuerte.<br> - Si <span class="math inline">\(2 \leq \log_{10} BF\)</span>, la evidencia a favor de <span class="math inline">\(H_0\)</span> es decisiva.</p>
</section>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>